# Infrastructure Documentation

This document provides an overview of the infrastructure of the Ask Analytics application deployed on Google Cloud Platform (GCP). This application allows internal users to query company analytics data stored in a BigQuery dataset and receive natural language responses. The infrastructure setup is manually implemented via the GCP console, without Infrastructure as Code (IaC). Deployment is done using the `gcloud deploy` command with environment variables passed via CLI.

## Components Overview

### Cloud Run Services

#### chatbot

- **Description**: This is the main application consisting of a FastAPI backend and a static frontend initially developed in TypeScript. Both components are containerised and deployed as a single Docker image.
- **Deployment**: The application is deployed to Cloud Run using the `gcloud deploy` command.
- **Environment Variables**: Secrets and other environment variables are passed via CLI during deployment.

#### langfuse

- **Description**: This service runs the LangFuse dashboard, used for logging and tracking interactions. The LangFuse Docker image is deployed to Cloud Run, and credentials are set up via the web application post-deployment.
- **Communication**: Public and private keys from LangFuse credentials are configured inside the LangFuse dashboard to allow communication between the chatbot and LangFuse services.

### BigQuery GA4 Dataset

- **Description**: The dataset contains Google Analytics 4 (GA4) data used for business intelligence. SQL queries generated by the chatbot are executed against this dataset.
- **Location**: The dataset resides in a separate GCP project dedicated to analytics.

### VertexAI

- **Description**: VertexAI is utilised for handling requests to large language models (LLMs). The chatbot sends requests to these models as part of the query resolution process.

### CloudSQL

- **Instance**: `chat-analytics`
  - **Databases**:
    - `chat-dev`: Used for logging various activities and data by the chatbot application.
    - `dev-langfuse`: Used by the LangFuse service for storing logs and tracking data.
    - `postgres`: Default database, currently not in use.

## Application Workflow

1. **User Interaction**: A user inputs a question via the frontend and submits it.
2. **Backend Processing**:
   - The backend sends a request to an LLM model via VertexAI to generate an appropriate SQL query.
   - The generated SQL is sanitised and possibly manipulated for optimisation.
   - The SQL query is executed against the BigQuery GA4 dataset.
   - The results are sent back to the LLM to generate a natural language response.
3. **Response Delivery**: The natural language response is returned to the frontend and displayed to the user.

## Logging and Tracking

- **LangFuse Service**: Logs interactions and tracking data.
- **CloudSQL**: The `chat-dev` database logs specific activities and data points for manual review and analysis.
  - Each time a new question is asked, the backend API creates a new "question" entry in the "Question" table of the `chat-dev` database, storing details such as user email, datetime, and the question asked.
  - Each time the LLM chain advances to the next step, a notification is automatically sent to the LangFuse instance, allowing it to populate its database. This logic is managed by LangFuse, a third-party service that we self-host and do not maintain directly.

## Notes

- This is a minimum viable product (MVP) and lacks Infrastructure as Code (IaC). Future iterations should consider implementing IaC for scalability and easier management.
- Manual steps in the GCP console include creating Cloud Run services, setting up environment variables, and configuring database instances.

For any questions or further details, please refer to the internal documentation or contact the development team.
